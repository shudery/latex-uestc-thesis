% !Mode:: "TeX:UTF-8"

\chapter{双目视觉系统的构建及实验总结}
经过前文对双目视觉系统的介绍，对双目视觉和立体匹配有了初步的了解，本章将在实验中实际搭建一个双目视觉系统，并实现一种基础的局部立体匹配方法，通过几种优化方法，提高立体匹配效果，降低匹配错误率。

在实验中，立体匹配方法的逻辑实现主要使用了框架OpenCV\citeup{A-4}，OpenCV是一个跨平台计算机视觉开源库，用C++语言编写，其主要的接口编程语言也是C++，但仍保留了大量的C语言接口，也有许多Python，MATLAB，Java接口可以使用。利用这个框架实现的函数可以快速搭建视觉系统，实现立体匹配功能。

\section{摄像机离线标定}
首先对摄像机进行离线标定，以获取摄像机的内外部参数，摄像机标定结果将用来纠正输入的左右图像，使图像只在水平方向上存在偏移，简化计算过程，这对于后面立体匹配的匹配效果影响很大。

离线标定方法采用张正友标定发，“张正友标定”又称“张氏标定”，是指张正友教授于1998年提出的单平面棋盘格的摄像机标定方法\citeup{A-15}。张氏标定法已经作为工具箱或封装好的函数被广泛应用，如OpenCV函数库中封装了张正友标定法的实现函数cvCalibrateCamera2。此文中所提到的方法，为相机标定提供了很大便利，并且具有很高的精度。用该方法标定可以不依赖于特殊的标定物，只需要一张打印出来的棋盘格。操作简单可行，本实验使用OpenCV实现张正友棋盘法来进行标定。

实验之前必须明确标定的三个问题：

相机标定的目的：获取摄像机的内部参数和外部参数矩阵，内参和外参系数可以对之后相机拍摄的图像就进行矫正，以得到畸变相对很小的图像。

相机标定的输入：标定图像上所有内角点的图像坐标，标定板图像上所有内角点的空间三维坐标（一般情况下假定图像位于Z=0平面上）。

相机标定的输出：摄像机固定不变的内部参数和外参系数。

这三个基础的问题就决定了使用Opencv实现张正友法标定相机的标定流程、标定结果评价以及使用标定结果矫正原始图像的完整流程：首先要准备标定图片，棋盘法常用棋盘如图\ref{4-3}所示。用摄像机拍摄多张拍摄图片，图片的位置和角度适当做一些改变，棋盘平面与摄像机坐标平面夹角不宜太大，获取多张样本可以减少实验误差，然后输入图像，提取每张照片的角点信息，进一步提取亚像素角点以提高标定精确度，在棋盘标定图上绘制内角点，对摄像机进行标定，查看标定结果并对其进行评估，获取内外参数矩阵。

\pic[h]{实验棋盘图}{keepaspectratio=false,height=4cm}{4-3}
	
具体实验过程，将双目摄像机安装固定好后，确保摄像机安置平面水平平整，由此假定摄像机的内参（包括焦距长度，透镜畸变参数等）和外参（旋转矩阵和平移矩阵）均固定。利用张正友标定方法，通过采集多组不同角度、距离的棋盘格图片，即可计算出摄像机的内外参数。这个步骤可以通过Matlab的标定工具离线完成。
采用Matlab平台对双目相机进行标定，标定方法采用张正友标定法，具体实现为OpenCV的cvCalibrateCamera2函数。

\begin{pics}[h]{采集的图像}{4}
\addsubpic{左摄像机}{keepaspectratio=false,height=5cm,width=7cm}{4-6}
\addsubpic{右摄像机}{keepaspectratio=false,height=5cm,width=7cm}{4-7}
\end{pics}

打印一张9x7的棋盘格，每个方格的边长为25mm，铺平贴到硬纸板上以便拍摄。尽量让棋盘格在左右图像中占30\%以上的比例，以便在标定过程中更加准确检测到角点，减少标定误差。用双目摄像机从不同角度、距离拍摄，得到多组图片。采集图片如图\ref{4-6}和\ref{4-7}所示。

将图像提取焦点后标定，Matlab输出定结果如图\ref{4-4}所示。

\pic[h]{标定结果}{keepaspectratio=false,height=8cm,width=12cm}{4-4}

整合所有角点信息，计算出摄像机的内外参数表\ref{4-8}

\pic[h]{内外参数记录表}{keepaspectratio=false,height=6.90cm}{4-8}

通过标定参数对采集图像进行纠正，可以使图像在垂直方向的坐标相同，这样视差就转变为计算左右视图水平坐标的距离，方便了视差的计算。

从图\ref{4-16}和图\ref{4-17}可以看到纠正图像后，图像的棋盘格子边缘与水平直线重合。

\begin{pics}[h]{采集的图像}{4}
\addsubpic{标定前左右图像位置}{keepaspectratio=false,height=4cm,width=7cm}{4-16}
\addsubpic{标定后左右图像位置}{keepaspectratio=false,height=4cm,width=7cm}{4-17}
\end{pics}

\section{实验过程匹配效果的评估}

立体匹配的过程，除了主观观察图像立体匹配效果，大多时候匹配误差没有办法直接主观地进行判断，需要通过某种客观的评估方法对匹配结果进行评估，以分析算法匹配精确度。

双目视觉系统在过去的很长一段时间里，业内一直没有一个统一的度量立体匹配
算法优劣的评判标准。直至 2002 年，Daniel 发表文章，首次提出了立体匹配算法的框架并建立了 Middlebury 网站的测评系统，并给出了一系列的标准测试图像。利用标准的测试图像，我们可以判断匹配效果与标准输出视差图的差距，从而得到算法的匹配精确度。该测评系统和测试图像自建立以来，一直被沿用至今，并且已经被广泛认可和采纳。

Daniel等人不仅提出了立体匹配算法的度量标准，还提供了四种用于测试算法的标准测试图像序列，代号分别为Tsukuba、Cones、Venus、Teddy，如图\ref{4-5}。这四种标准图涵盖了许多拍摄场景的布局和光照情况，为了避免标定的内外参数误差对立体匹配效果的影响，已经方便客观地输出立体匹配精确度，实验过程中将先采用Middlebury网站提供的标准左右图，最后将匹配结果与网站提供的标准视差图对比评估。

\pic[h]{四种标准图像}{keepaspectratio=false,height=8cm,width=15cm}{4-5}

Middlebury 网站除了提供纠正过的标准左右图像，还有提供图像准确的的遮挡区域图\ref{4-20}所示，也提供了准确的视差图\ref{4-2}，这些图像信息都是经过严格匹配的结果。有了这些标准图像，我们就可以利用评估函数对匹配方法的准确性进行测试。

\pic[h]{四种标准图像的遮挡区域图}{keepaspectratio=false,height=6cm,width=8cm}{4-20}
\pic[h]{四种标准图像的准确视差图}{keepaspectratio=false,height=8.5cm}{4-2}

有了标准左右图像和标准视差图，只要将匹配结果与标准视差按某种度量方法进行比对，就能得到一个客观的立体匹配精确度。常用的度量方法有RMS（root-mean-squared）和 POBMP（Percentage of bad matching pixels）

本实验将通过编程实现一个基于POBMP度量标准的立体匹配算法评估函数，直接统计误匹配的像素占图像整体像素的百分比，即误匹配率，POBMP公式：
\begin{equation}
POBMP=\frac{1}{N}\sum_{(x,y)} (|\ d_{c}(x,y)-d_{t}(x,y)\ |>\delta _{d})
\end{equation}

其中，$d_{c}(x,y)$是计算出来的视差图中像素$(x,y)$的视差值，$d_{t}(x,y)$是真实视差图中像素$(x,y)$的视差值，$\delta _{d}$是视差值的误差阈值，通常取1，N是图像中像素的总个数。通过输入middlebury的标准匹配视差图和实际匹配输出视差图进行对比，计算得出误匹配率。

算法执行速度的评估则直接根据C语言头函数time.h库自带的时间打点记录函数来计算算法的执行时间。

\section{局部立体匹配SAD算法实现}

双目视觉系统的关键模块就是立体匹配方法的实现，本节将以经典的局部立体匹配方法SAD为例，实现一次完整的局部立体匹配过程。

\pic[h]{局部匹配算法流程图}{keepaspectratio=false,height=8cm}{3-4}

局部匹配算法在匹配代价聚合过程中有多种相似性测度函数，如绝对误差和(the Sum of Absolute Differences,简称SAD)，平方误差和(the Sum of Squared Differences,简称 SSD)，归一化互相关(normalized cross correlation,简称 NCC)等，SAD是最简单的一种，其的计算公式为：
\begin{equation}
SAD(x,y,d)=\sum_{(x,y)\in N_{L}} |\ I_{1}(x,y)-I_{2}(x,y+d) \ |
\end{equation}

其中，$N_{L}$是以参考点 $(x,y)$ 为中心的参考窗口，$R_{N}$是以目标点$(x,y+d)$为中心的目标窗口，$d$为视差，$I_{1}$为参考图像，$I_{2}$为目标图像。该算法分别以参考点$(x,y)$和目标点$(x,y+d)$为中心，在参考窗口$L_{N}$和目标窗口$R_{N}$中统计窗口内对应位置像素的灰度值和的差，以此作为参考窗口$L_{N}$和目标窗口$R_{N}$的误差。
在给定的视差取值范围内遍历所有的目标窗口，使误差SAD取值最小的目标窗口对应的视差值d即为参考点$(x,y)$的视差值。SSD算法只是更改相似性函数的计算方法，将绝对值误差替换为平方值误差，其他方法步骤相同。

\pic[h]{SAD算法过程示意图}{keepaspectratio=false,height=5.5cm,width=8.5cm}{3-3}

SAD算法具体的执行步骤为：

(1) 以左图像像素点为中心构造一个小窗口，类似于卷积和。

(2) 用同等大小的窗口覆盖右图像同一垂直坐标的区域，水平移动遍历所有可能窗口。

(3) 在每一个可能窗口内，遍历依次选取窗口内的像素点。 

(4) 左图像像素点坐标减去右图像像素点坐标，求出同一窗口内所有像素点差的绝对值之和。

(5) 同理，依次计算所有参考窗口。

(6) 找到同一垂直坐标范围内SAD值最小的窗口，该窗口的中心像素点就是左图像中心像素的最佳匹配，它们的差值就是视差。

(7) 同理执行所有左图像素点，得到所有像素的视差，输出视差图。

用OpenCV函数读入标准图像信息，利用C语言编写代码实现上述逻辑过程，以Tsukuba标准图，构造窗口大小取11为例，实现的SAD算法立体匹配视差图像如\ref{4-10}所示。

\pic[h]{Tsukuba立体匹配效果：(a)左图像 (b)右图像 (c)SAD匹配视差图 (d)标准视差图}{keepaspectratio=false,height=9cm,width=12cm}{4-10}

\section{匹配窗口的选择}

在研究与应用中发现，基于区域相似度的匹配算法的可靠性会受所选取支持窗口的大小影响：支持窗口越大，匹配信息越丰富，在低纹理区域或重复区域匹配效果越好，但是在细节复杂、视差不连续区域或者闭塞区域误匹配率越高;支持窗口越小，在视差
不连续区域和闭塞区域的误匹配越少，但是在低纹理区域信息采集越不充足、误匹配率
越高。出现这种矛盾的情况是因为，在匹配过程中需要收集尽可能多的正确有效的参考
信息用于相似度测量，为了采集更多参考信息，支持窗口需要增大，但是随着支持窗口
增大，支持窗口内的闭塞区域信息也会增多，闭塞区域的信息是无效信息甚至是干扰信
息，参考信息可靠性降低将直接影响匹配准确率。
\pic[h]{各标准图窗口大小与误匹配率的关系表}{keepaspectratio=false,height=9cm}{4-30}

利用实现的评估函数算法和标准视差图，我们可以通过输入不同的窗口大小值，得出误匹配率，输入常用的窗口边长大小，进行多次试验，对比各个窗口SAD算法的误匹配率，可以得出其关系如表\ref{4-30}所示，又该折线图可以判断标准图像的输出视差图在N=17时误匹配率最低，当N大于8之后误匹配率上升，而且随着选择窗口的变大，算法每一轮循环需要遍历的像素点越多，算法的时间复杂度提高，导致运行时间开始增加，局部匹配的优点之一就是匹配速度较快，综上可以得出标准图的匹配窗口大小N=17时图像匹配效果最好。各标准图在不同窗口大小下的输出视差图效果如图\ref{4-31}-(d)所示。

\begin{pics}[h]{不同窗口大小视差图}{4}
\addsubpic{Teddy}{keepaspectratio=false,width=14cm,height=2.75cm}{4-31}
\addsubpic{Cones}{keepaspectratio=false,width=14cm,height=2.75cm}{4-32}
\addsubpic{Venus}{keepaspectratio=false,width=14cm,height=2.75cm}{4-33}
\addsubpic{Tsukuba}{keepaspectratio=false,width=14cm,height=2.75cm}{4-34}
\end{pics}

\section{优化局部立体匹配算法}

上文通过调用相关函数库，编写算法逻辑，已经实现了基础的局部立体匹配方法SAD，本节将研究立体匹配过程中的常见难题，如左右输入图像曝光不一致，导致灰度信息缺乏可信度，遮挡现象影响匹配，中心像素点对匹配窗口内所有像素点依赖一致等等，对这些可能遇到的问题进行算法优化，提高算法的稳定性，降低误匹配率。

\subsection{增加Census变换}

\pic[h]{Census变换示意图1}{keepaspectratio=false,height=3cm,width=14cm}{3-6}

由于SAD算法的相似性测度函数采用窗口对应点的灰度值直接计算，没有考虑窗口各点与中心点的相关性，因此受窗口大小和环境影响较大。比如左右图像曝光时间或光照条件不同导致的左右图像对应区域灰度值差距大。可以采用Census变换方法，先将窗口内各点的灰度值转换为与窗口中心相关的数值，将绝对的灰度条件，转换为相对灰度条件，以此解决图像的灰度信息不同步的问题，提高精确度。

具体过程是在参考窗口（即左窗）和目标窗口（即右窗）中分别作
如下计算：遍历窗口中的每一个像素，若该像素灰度值大于中心像素灰度值，则
该像素置 1，否则置 0，如公式 4-3 所示
\begin{equation}
Census(q)=\left\{\begin{matrix}
1 & I(q)>I(p) \\ 
0 & otherwrise 
\end{matrix}\right.
\end{equation}
其中，p 为非中心像素，q 为中心像素。 $I(q)$为非中心像素的灰度值，$ I(p)$为
中心像素的灰度值。如图 \ref{3-7} 所示，$N_{L}$ 和 $CensusN_{L}$ 分别为变换前后的窗口。
\pic[h]{Census变换示意图2}{keepaspectratio=false,height=12cm}{3-7}

在分别对参考窗口 $N_{L}$ 和目标窗口 $N_{R}$ 进行 Census 变换之后，就得到了两个仅由 0 和 1 组成的二进制串 $N_{L01}$ 和 $N_{R01}$ ，如图 3.6 所示。由于汉明距离表示两个码串之间对应位置不同码字的位的个数，这样，就可以通过比较 $N_{L01}$ 和 $N_{R01}$ 之间的汉明距离来度量参考窗口 $N_{L}$ 和目标窗口 $N_{R}$ 之间的相似度。易知，$N_{L01}$ 和 $N_{R01}$ 之间的汉明距离为13。同理，在视差值的取值范围内移动目标窗口，分别计算对应的汉明距离，最后再用赢者通吃算法（WTA）筛选出误差值即可。

在传统的基于 Census变换的局部立体匹配算法中，在对窗口中的像素灰度值进行 Census变换时参考的是中心像素的灰度值。由于图像中像素的灰度值受很多外界不确定因素的影响，因此，如果中心像素不够准确，则比较结果的误差将会增加。为了减小误差，在改进的基于Census 变换的局部立体匹配算法中，在对窗口中的像素进行 Census 变换时，不直接采用窗口中像素的灰度值直接计算，而是采用像素灰度值相对中心像素的大小来综合对比，这样就可以减少由于窗口曝光的不一致而造成的匹配误差。

以Teddy标准图为例，通过对图像输入灰度值的调整，模拟左右摄像图片曝光不一致的情形，通过对输入像素进行Census变换，转换为二进制串进行对比，经过多次试验，基础的SAD算法误匹配率在15.23\%左右，经过Census变换后的误匹配率为12.89\%左右，实际的匹配效果如图\ref{4-40}所示，添加Census变换后立体匹配在面对曝光不一致的情况下噪点情况得到改善，降低了误匹配率。
\pic[h]{Teddy匹配效果：(a)SAD算法 (b)Census变换优化}{keepaspectratio=false,height=5cm}{4-40}

\subsection{双向匹配遮挡检测}

立体匹配过程中存在遮挡现象。由于摄像机平移的特点，在相机平移过程中必然会出现前景物体将后景物体边缘遮挡的情形，此时左图像的点在右图中无法找到准确的匹配点，这部分区域就是遮挡区域。

添加遮挡区域检测，以提高图片遮挡区域的匹配准确率。可以通过对换参考图像和目标图像，进行双向匹配，比较两次输入得到的视差图，视差值大于一定阈值的区域就是遮挡区域。

\pic[h]{Tsukuba匹配效果：(a)SAD方法 (b)检测到的遮挡区域 (c)添加遮挡填充的SAD}{keepaspectratio=false,height=5cm,width=15cm}{4-14}

以左图为参考图像，右图为目标图像，即在右图中寻找左图中每一个像素对应的像素点，从而获取左图对应的视差图。但是，这样单向匹配的结果就是，在左图中，有些像素得到了正确的匹配，有些像素得到了错误的匹配。 如果匹配的结果是正确无误的，那么不管以左图和右图中的哪一副为参考图像，另外一副为目标图像，那么匹配的结果都应该是一致的，而在图像的遮挡区域，肯定得不到正确的匹配，因此两次匹配的结果应该是不一致的，这就是双向匹配算法的思想。以此改进算法，添加遮挡检测，并在遮挡区域选择视差较小的背景视差对视差图进行遮挡填充。以Tsukuba标准图为例，实验过程得到的SAD匹配效果，遮挡检测输出的遮挡区域，以及添加遮挡填充的SAD算法如图\ref{4-14}所示。

分析图\ref{4-14}中可以得知，在没有添加遮挡检测的SAD算法输出视差图中噪点较多，且大部分落在了遮挡区域内，通过检测遮挡区域，降低了在该区域内误匹配率，从而得到匹配效果更准确的视差图。通过评估函数计算，未优化的SAD算法误匹配率在15.22\%左右，添加遮挡检测后降低到13.52\%左右。

\subsection{基于几何距离的自适应权重}

在SAD算法中，窗口中每一个像素点计算出来的基元对于窗口中心点来说权重是一致的，这其实并不符合常理，距离窗口中心比较近的区域应该比比较远的地方的像素点信息更有参考意义，如果不通过一些方法去除这种一致性，那么算法的匹配准确度将会非常依赖于窗口大小的选择。

在双目立体视觉中，图像对中的遮挡等闭塞、视差不连续情况是普遍存在的，而且这种存在的可能性随支持窗口的增大而增大，邻域点离中心点越远匹配可靠性和参考价值越小，这种特性也是符合人眼视觉特性的。

\pic[h]{人类双眼关注度与关注中心的相关性示意图}{keepaspectratio=false,height=5cm}{3-9}

根据邻域点至窗口中心的几何距离分配匹配权重的模型,几何距离权重$f_{w}$的表达式如公式: 
\begin{equation}
f_{w}(i,j) = a\omega ^{f^{s}}
\end{equation}

式中,$(i,j)$为邻域点在窗口中的坐标，$f=\sqrt{i^{2}+j^{2}}$是邻域点至窗口中心的几何距离。$a,s$和$\omega$为权重调节因子：$a$为幅值调节因子，可避免计算结果下界溢出；$\omega$为指数衰减速度调节因子，$\omega$越大特征曲线越平滑；$s$为峰度调节因子，$s$越大特征曲线越窄。$s$和$\omega$共同作用控制核心区的范围和权重系数，本实验中这些常数因子取常用经验值进行计算。

由于距离窗口中心点距离越远其提供的信息参考价值越小，通过基于几何距离自适应权重，距离中心像素点越远，相似性函数计算得出的结果被权重系数削弱影响就越明显，以此解决窗口内像素点贡献无差异的问题，从而提高低纹理和深度非连续区域的匹配准确性。

在SAD算法公式的基础上，每一个窗口匹配像素点在计算灰度值差值后，乘以基于几何距离计算出来的权重值，然后再保存，最后将窗口所有像素点统计相加，得到最佳的匹配点，输出视差图。本实验以Venus标准图为例子，经过几何距离自适应权重之后的匹配效果如图\ref{4-44}所示，观察分析可以看出图像噪点明显减少，误匹配的情况有所改善。将输出的视差图分别用评估函数进行计算，得到优化后的匹配算法误匹配率从原来的15.39\%下降到了11.77\%。

\pic[h]{Tsukuba匹配效果：(a)SAD方法 (b)基于几何距离自适应权重}{keepaspectratio=false,height=5cm}{4-44}

\section{实验结论及全文最后总结}

上一节通过多个角度，针对立体匹配过程中存在的问题，局部匹配方法SAD存在的缺陷进行优化，分析实际的匹配效果以及通过评估函数计算得到的误匹配率变化，验证了优化方法的有效性。综合所有优化过程步骤，即给SAD算法添加Census变换，遮挡检测以及依据几何距离的自适应权重，对输入图像进行立体匹配，得到如图\ref{4-50}所示的匹配效果，可以看到输出视差图噪点明显减少，在深度不连续和低纹理区域的匹配能力都有所改善。

\pic[h]{优化效果对比：(a)Teddy (b)Venus (c)Cones (d)Tsukuba}{keepaspectratio=false,width=14cm}{4-50}

将优化前后的输出视差图，输入到评估函数与标准视差图进行比对，对前后匹配效果进行量化，得到的误匹配率变化如图\ref{4-51}所示，相比基础的SAD算法，优化后的立体匹配方法在不同的标准图测试过程中都在一定程度上降低了误匹配率，从而验证了优化的真实有效。
\pic[h]{算法优化前后的误匹配率}{keepaspectratio=false,height=4cm}{4-51}

至此，实验最终实现了一个双目视觉系统的基本功能，通过标定纠正采集的图像，实现了基于局部立体匹配的图像匹配效果，通过多种方式优化局部匹配方法，利用评估函数对比算法匹配效果，最终得要一种匹配效率较高的立体匹配方法，达到实验目的。

经过本课题的学习研究，了解了一些计算机视觉的基础知识，掌握了一个双目视觉系统的基本原理和实现方法，通过对立体匹配的学习，对匹配难点的思考，针对匹配过程中的常见问题，本课题从多个角度来优化算法，并得到满意结果，提高了匹配准确率。从这个过程中锻炼了思考解决实际问题的能力，完成匹配要求的同时也提高了编程能力。

计算机视觉领域现在正在快速发展，经过课题的研究学习，我对双目视觉有了粗浅的入门，掌握了基本的三维重建原理。我对计算机视觉的发展前景和应用场景普及十分看好，希望在各领域学者和企业的共同努力下，加速计算机视觉的发展，在多个领域为人类提供便捷的服务。