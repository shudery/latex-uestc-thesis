% !Mode:: "TeX:UTF-8"

\chapter{双目视觉系统的构建及实验总结}
经过前文对双目视觉系统的介绍，接下我们将在实验中实际搭建一个双目视觉系统，并实现一种基础的立体匹配方法，通过不断优化这个算法提高匹配的精确度。

在本实验中，立体匹配方法实现主要是利用了计算机视觉函数库OpenCV，用C语言实现算法逻辑。

\section{摄像机离线标定}
摄像机标定结果将用来纠正输入的左右图像，这对于后面立体匹配的匹配效果影响很大。实验使用OpenCV实现经典的棋盘法标定，棋盘如图\ref{4-3}所示。
\pic[h]{实验棋盘图}{keepaspectratio=false,height=6cm}{4-3}

实验之前必须明确标定的三个问题：

相机标定的目的：获取摄像机的内参和外参矩阵（同时也会得到每一幅标定图像的选择和平移矩阵），内参和外参系数可以对之后相机拍摄的图像就进行矫正，得到畸变相对很小的图像。

相机标定的输入：标定图像上所有内角点的图像坐标，标定板图像上所有内角点的空间三维坐标（一般情况下假定图像位于Z=0平面上）。

相机标定的输出：摄像机的内参、外参系数。

这三个基础的问题就决定了使用Opencv实现张正友法标定相机的标定流程、标定结果评价以及使用标定结果矫正原始图像的完整流程：

1. 准备标定图片

2. 对每一张标定图片，提取角点信息

3. 对每一张标定图片，进一步提取亚像素角点信息

4. 在棋盘标定图上绘制找到的内角点（非必须，仅为了显示）

5. 相机标定

6. 对标定结果进行评价

7. 查看标定效果——利用标定结果对棋盘图进行矫正

双目相机确定好后，摄像机的内参（包括焦距长度，透镜畸变参数等）和外参（旋转矩阵和平移矩阵）均固定。利用张正友标定方法，通过采集多组不同角度、距离的棋盘格图片，即可计算出摄像机的内外参数。这个步骤可以通过Matlab的标定工具离线完成。
采用Matlab平台对双目相机进行标定，标定方法采用张正友标定法。打印一张9x7的棋盘格，每个方格的边长为25mm，铺平贴到硬纸板上以便拍摄。尽量让棋盘格在左右图像中占30\%以上的比例，以便在标定过程中更加准确检测到角点，减少标定误差。用双目摄像机从不同角度、距离拍摄，得到多组图片。采集图片如图\ref{4-6}和图\ref{4-7}所示:

\pic[h]{采集左图像}{keepaspectratio=false,height=6cm}{4-6}
\pic[h]{采集右图像}{keepaspectratio=false,height=6cm}{4-7}

将图像提取焦点后标定，得出的标定结果。
\pic[h]{标定结果}{keepaspectratio=false,height=6cm}{4-4}
\pic[h]{内外参数记录表}{keepaspectratio=false,height=6cm}{4-8}

\section{实验过程匹配效果的评估}

在之前的很长一段时间里，立体匹配领域一直没有一个统一的度量立体匹配
算法优劣的评判标准。直至 2002 年，Daniel 发表文章，首次提出了立体匹配算法
的框架并建立了 Middlebury 网站的测评系统，并给出了一系列的标准测试图像。
该测评系统和测试图像自建立以来，一直被沿用至今，并且已经被广泛认可和采
纳。

常用的度量方法包括RMS（root-mean-squared）和 POBMP（Percentage of bad matching pixels）

本实验的评估函数使用POBMP度量标准，直接统计误匹配的像素占图像整体像素的百分比，即误匹配率：

{{{公式}}}

其中，dc(x, y)是计算出来的视差图中像素(x, y)的视差图，dT(x, y)是真实视差图中像素(x, y)的视差值，d是视差值的误差阈值，通常取1，N是图像中像素的总个数。通过输入middlebury的匹配效果图和实际匹配结果，计算得出误匹配率。

Daniel 等人不仅给出了立体匹配算法的度量标准，更给出了用于测试算法的标准测试图像序列，如图\ref{4-5}。实验过程中将先采用Middlebury网站提供的标准左右图，并将匹配结果与网站提供的标准视差图对比评估。

\pic[h]{四种标准图像}{keepaspectratio=false,height=6cm}{4-5}

除了纠正过的标准左右图像，还有图像的遮挡区域，视差图等，以网站提供的Tsukuba图为例，如图\ref{4-2}所示，起图像信息都是经过严格匹配的结果。有了这些标准图像，我们就可以利用评估函数对匹配方法的准确性进行测试。

\pic[h]{Tsukuba图像信息}{keepaspectratio=false,height=6cm}{4-2}

算法执行速度的评估则直接根据C语言头函数time.h库自带的时间打点记录函数来计算算法的执行时间。

\section{局部立体匹配SAD算法实现}

本节将以经典的局部立体匹配方法SAD为例，展开介绍一次完整的局部立体匹配过程。

\pic[h]{局部匹配算法流程图}{keepaspectratio=false,height=6cm}{3-4}

局部匹配算法在匹配代价聚合过程中有多种相似性测度函数，如绝对误差和(the Sum of Absolute Differences,简称SAD)，相似的还有平方误差和(the Sum of Squared Differences,简称 SSD)，归一化互相关(normalized cross correlation,简称 NCC)等，SAD是最简单的一种，其的计算公式为：

{{{公式}}}

其中，LN是以参考点 (x, y) 为中心的参考窗口，RN是以目标点(x, y+d)为中心的目标窗口，d为视差，I1为参考图像，I2为目标图像。该算法分别以参考点(x, y)和目标点(x, y+d)为中心，在参考窗口LN和目标窗口RN中统计窗口内对应位置像素的灰度值和的差，以此作为参考窗口LN和目标窗口RN的误差。
在给定的视差取值范围内遍历所有的目标窗口，使误差SAD取值最小的目标窗口对应的视差值d即为参考点(x, y)的视差值。SSD算法只是更改相似性函数的计算方法，将绝对值误差替换为平方值误差，其他方法步骤相同。

\pic[h]{SAD算法过程示意图}{keepaspectratio=false,height=6cm}{3-3}

SAD算法基本流程：

•  构造一个小窗口，类似与卷积和。

•  用窗口覆盖左图像，选择出覆盖区域内的所有像素点。 

•  用窗口覆盖右图像，选择出覆盖区域内的所有像素点。

•  左覆盖区域减去右覆盖区域，求出所有像素点差的绝对值之和。

•  移动右图像的窗口，判断是否超出搜索范围，否则继续重复上两步。

•  找到这个范围内SAD值最小的窗口，即找到了左边图像的最佳匹配。

用OpenCV函数读入标准图像信息，利用C语言编写代码实现上述逻辑过程，以Tsukuba标准图，构造窗口大小取8为例，输出视差图像如图\ref{4-10}所示。

\pic[h]{Tsukuba经过实验算法匹配输出视差图}{keepaspectratio=false,height=6cm}{4-10}

\section{匹配窗口的选择}

在研究与应用中发现，基于区域相似度的匹配算法的可靠性会受所选取支持窗口的大小影响：支持窗口越大，匹配信息越丰富，在低纹理区域或重复区域匹配效果越好，但是在细节复杂、视差不连续区域或者闭塞区域误匹配率越高;支持窗口越小，在视差
不连续区域和闭塞区域的误匹配越少，但是在低纹理区域信息采集越不充足、误匹配率
越高。出现这种矛盾的情况是因为，在匹配过程中需要收集尽可能多的正确有效的参考
信息用于相似度测量，为了采集更多参考信息，支持窗口需要增大，但是随着支持窗口
增大，支持窗口内的闭塞区域信息也会增多，闭塞区域的信息是无效信息甚至是干扰信
息，参考信息可靠性降低将直接影响匹配准确率。

利用实现的评估函数算法和标准视差图，我们可以通过输入不同的窗口大小值，得出误匹配率，多次试验可以得出其关系如表\ref{4-12}所示，匹配算法运行时间如表\ref{4-13}所示。

\pic[h]{各标准图窗口大小与误匹配率的关系表（单位：\%）}{keepaspectratio=false,height=6cm}{4-12}
\pic[h]{各标准图窗口大小与匹配速度的关系表（单位：s）}{keepaspectratio=false,height=6cm}{4-13}

在窗口大小为N=8时匹配误匹配率较低，当N>8之后误匹配率上升或者变换不大，而且算法运行时间开始大幅增加，所以可以得出标准图的整体最佳匹配窗口大小为8

\section{优化实验算法}

针对匹配过程中可能遇到的问题，通过对SAD算法进行优化以提高算法的匹配精准度。

\subsection{增加Census变换}

\pic[h]{Census变换示意图1}{keepaspectratio=false,height=6cm}{3-6}

由于SAD算法的相似性测度函数采用窗口对应点的灰度值直接计算，没有考虑窗口各点与中心点的相关性，因此受窗口大小和环境影响较大。比如左右图像曝光时间或光照条件不同导致的左右图像对应区域灰度值差距大。可以采用Census变换方法，先将窗口内各点的灰度值转换为与窗口中心相关的数值，如若灰度大于中心值灰度则取1，小于则取2，这样就将绝对的灰度条件，转换为相对灰度条件，以此解决图像的灰度信息不同步的问题，提高精确度。

\pic[h]{Census变换示意图2}{keepaspectratio=false,height=6cm}{3-7}

在分别对参考窗口LN 和目标窗口RN 进行 Census 变换之后，就得到了两个仅由 0 和 1 组成的 01 串L01N 和R01N ，如图 3.6 所示。由于汉明距离表示两个码串之间对应位置不同码字的位的个数，这样，就可以通过比较L01N 和R01N 之间的汉明距离来度量参考窗口LN 和目标窗口RN 之间的相似度。易知，L01N 和R01N 之间的汉明距离为13。同理，在视差值的取值范围内移动目标窗口，分别计算对应的汉明距离，最后再用赢者通吃算法（WTA）筛选出误差值即可。

在传统的基于 Census变换的局部立体匹配算法中，在对窗口中的像素灰度值进行 Census变换时参考的是中心像素的灰度值。由于图像中像素的灰度值受很多外界不确定因素的影响，因此，如果中心像素不够准确，则比较结果的误差将会增加。为了减小误差，在改进的基于Census 变换的局部立体匹配算法中，在对窗口中的像素进行 Census 变换时，不直接采用窗口中心像素的灰度值，而是采用整个窗口中所有像素灰度值的平均值作为比较对象，这样就可以减少由于中心像素的不准确而造成的匹配误差。 

\subsection{双向匹配遮挡检测}

立体匹配过程中存在遮挡现象。由于摄像机平移的特点，在相机平移过程中必然会出现前景物体将后景物体边缘遮挡的情形，此时左图像的点在右图中无法找到准确的匹配点，这部分区域就是遮挡区域。

\pic[h]{遮挡区域示意图}{keepaspectratio=false,height=6cm}{3-8}

添加遮挡区域检测，以提高图片遮挡区域的匹配准确率。可以通过对换参考图像和目标图像，进行双向匹配，比较两次输入得到的视差图，视差值大于一定阈值的区域就是遮挡区域。

以左图为参考图像，右图为目标图像，即在右图中寻找左图中每一个像素对应的像素点，从而获取左图对应的视差图。但是，这样单向匹配的结果就是，在左图中，有些像素得到了正确的匹配，有些像素得到了错误的匹配。 如果匹配的结果是正确无误的，那么不管以左图和右图中的哪一副为参考图像，另外一副为目标图像，那么匹配的结果都应该是一致的，而在图像的遮挡区域，肯定得不到正确的匹配，因此两次匹配的结果应该是不一致的。以此改进算法，添加遮挡检测，并在遮挡区域选择视差较小的背景。以Tsukuba标准图为例，如图\ref{4-14}所示。

\pic[h]{遮挡检测前后匹配效果对比}{keepaspectratio=false,height=6cm}{4-14}

在图\ref{4-14}中可以看到，没有添加遮挡检测的视差图噪点较多，且大部分落在了遮挡区域内，通过检测遮挡区域，降低了在该区域内误匹配的概率，得到了匹配效果较好的视差图。

\subsection{基于几何距离的自适应权重}

在SAD算法中，窗口中每一个像素点计算出来的基元对于窗口中心点来说权重是一致的，这其实并不符合常理，距离窗口中心比较近的区域应该比比较远的地方的像素点信息更有参考意义，如果不通过一些方法去除这种一致性，那么算法的匹配准确度将会非常依赖于窗口大小的选择。

在双目立体视觉中，图像对中的遮挡等闭塞、视差不连续情况是普遍存在的,而且这种存在的可能性随支持窗口的增大而增大，邻域点离中心点越远匹配可靠性和参考价值越小，这种特性也是符合人眼视觉特性的。

\pic[h]{人类双眼关注度与关注中心的相关性示意图}{keepaspectratio=false,height=6cm}{3-9}

根据邻域点至窗口中心的几何距离分配匹配权重的模型,几何距离权重f的表达式如公式: 

{{{公式}}}

式中,(i,j)为邻域点在窗口中的坐标，f=是邻域点至窗口中心的几何距离。a、s和w为权重调节因子：a为幅值调节因子，可避免计算结果下界溢出；w为指数衰减速度调节因子，w越大特征曲线越平滑；S为峰度调节因子，S越大特征曲线越窄。S和w共同作用控制核心区的范围和权重系数。

由于距离窗口中心点距离越远其提供的信息参考价值越小，通过基于几何距离自适应权重，来解决窗口内像素点贡献无差异的问题，从而提高低纹理和深度非连续区域的匹配准确性。

在SAD算法公式的基础上，每一个窗口匹配像素点在计算灰度值差值后，乘以几何距离权重保存，最后将窗口所有像素点统计相加，得到最佳匹配点，输出视差图。以Tsukuba为例，经过几何距离自适应权重之后的匹配效果如图\ref{4-15}所示，误匹配率从原来的8.39\%下降到了6.77\%。

\pic[h]{几何距离自适应权重优化效果对比}{keepaspectratio=false,height=6cm}{4-15}

\section{实验结论及全文最后总结}
