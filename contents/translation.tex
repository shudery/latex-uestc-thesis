% !Mode:: "TeX:UTF-8"

\chapter{基于优化的匹配算法高效获取视差图}

本文提出改进的常规误差绝对和（SAD）算法，从而改进立体相机感应物体深度距离的性能。 基础的SAD算法通常在整个立体图像中搜索信息，以找出左右拍摄图像之间的像素视差，然后获得相应的视差图，这可能导致大量的运算时间损耗。为了减少数量搜索像素，建议改进的SAD算法尝试仅仅计算被称为兴趣像素的边缘像素的视差，并提供有关深度图的重要信息。该方法能够使正在搜索的像素数减少占总像素大约17％的像素数，因此与传统SAD相比总时间节省了89％左右。 这个结果有望实现实时的视觉系统。

立体匹配是一个关于如何找到两个输入图像之间的对应关系的问题。 它是广泛应用的基础计算机视觉问题之一，因此近年来在计算机视觉领域得到了人们广泛的关注和研究。立体匹配目标是为左边图像中的每个像素点，找到它在右图像的对应像素点点。这些点的水平距离之间的差值就是视差值，视差图由图像中的所有像素点的视差值组成。实际应用中的地图基本上是感知场景的深度距离，视差图可以用来解决诸如3D重建，定位，移动机器人导航，障碍物回避等许多领域的问题。

如今有三种广泛的技术被用于立体匹配：基于区域的，基于特征和基于相位的立体匹配方法。基于SAD的立体匹配实现是实时立体视觉中最有利的一种基于区域匹配的技术，因为它可以在硬件中直接实现。设计算法很简单，仅执行求和和绝对值。可以使用并行设计单元来达到误差范围，以减少所需的运算时间。可以应用SAD相关算法来解决机器人控制和映射中自动检测模具应用的问题。研究结果表明，SAD算法可以成为Lowe在地标选择问题中提出的SIFT方法的潜在替代方法。 SIFT方法的目的是为全功能恒定速率，旋转，移动物体提供匹配方法，但SAD方法被证明在再现3D或导航服务时更有效。

通常将视差定义为以右图像坐标为基准观察到的左图像对应像素点的偏移量，通过确定右图像中每个像素处对应的SAD值来计算视差。在对所有的有效差值进行SAD匹配相似度计算之后，产生最低SAD的像素点将被视为图像中该位置像素点的匹配值。对立体图像的所有像素点执行视差计算，由于该方法可能受到目标对象的位置和大小的影响，必须先确定两个图像之间的对应点，特别是对于捕获的动态图像或帧的巨大尺寸。

本文所提出的SAD算法尝试通过利用从捕获的立体图像提取的边缘信息，通过这些信息来修正视差值的输出结果。由于在所提出的方法中使用的边缘算子可以减少运算时长，所以可以以较短的时间来得到视差图，同时保持视差图匹配效果。